---
title: "lab report knapsack"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{lab report knapsack}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(Lab6)
```

# Introduction

This vignette serves as the **lab report** for **Lab 6** in *Advanced R Programming*.

The purpose of this lab is to explore **algorithmic complexity** and **computational performance** using the **Knapsack problem**.


# The Knapsack Problem

The **Knapsack problem** is a classic *discrete optimization problem*.  
We have a knapsack that can carry a limited weight `W`, and we want to fill it with `n` items, each item `i` having a weight `wᵢ` and a value `vᵢ`.  
The goal is to **maximize the total value** of the selected items without exceeding the weight limit.

Formally:

$$
\text{maximize} \quad \sum_{i=1}^n v_i x_i \\
\text{subject to} \quad \sum_{i=1}^n w_i x_i \le W, \quad x_i \in \{0,1\}
$$

This problem is **NP-hard**, meaning that it’s at least as hard as the hardest problems in NP.  
No polynomial-time algorithm is known for solving it optimally (this is an open Millennium Prize problem).  
For background, see the [Wikipedia page on the Knapsack problem](https://en.wikipedia.org/wiki/Knapsack_problem).

---

# Data Generation

The data for this lab is generated as follows.  
To create larger datasets, you can increase the value of `n`.  
Be careful with the random number generator version to ensure reproducibility.

```{r}
# Ensure consistent random number generation
RNGversion(min(as.character(getRversion()), "3.5.3"))
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")

# Number of items
n <- 2000

# Generate weights and values
knapsack_objects <- data.frame(
  w = sample(1:4000, size = n, replace = TRUE),
  v = runif(n = n, 0, 10000)
)

# Display first few rows
head(knapsack_objects)
```



# 1.1.2 Brute force search

Question: How much time does it takes to run the algorithm for n = 16 objects?


## How much time does it take for n = 16 objects?

To evaluate the performance of the brute-force algorithm, we can measure the execution time when solving a knapsack problem with **16 items**.  
Since the algorithm checks all \( 2^{16} = 65,536 \) possible combinations, it should still be feasible to compute — but noticeably slower than smaller cases.

```{r brute-force-timing, cache = TRUE}
# Generate data for 16 objects
RNGversion(min(as.character(getRversion()), "3.5.3"))
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")

n <- 16
knapsack_objects <- data.frame(
  w = sample(1:4000, size = n, replace = TRUE),
  v = runif(n = n, 0, 10000)
)

# Measure computation time
system.time({
  result <- brute_force_knapsack(knapsack_objects, W = 3500)
})

result
```



# 1.1.3 Dynamic programming

## How much time does it takes to run the algorithm for n = 500 objects?

```{r dynamic-programming, cache = TRUE}
# Generate data for 500 objects
RNGversion(min(as.character(getRversion()), "3.5.3"))
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")

n <- 500
knapsack_objects <- data.frame(
  w = sample(1:4000, size = n, replace = TRUE),
  v = runif(n = n, 0, 10000)
)

# Measure computation time
system.time({
  result <- knapsack_dynamic(knapsack_objects, W = 3500)
})

result
```

# 1.1.4 Greedy heuristic

## How much time does it takes to run the algorithm for n = 1000000 objects?
```{r greedy-knapsack, cache = TRUE}
# Generate data for 500 objects
RNGversion(min(as.character(getRversion()), "3.5.3"))
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")

n <- 1000000
knapsack_objects <- data.frame(
  w = sample(1:4000, size = n, replace = TRUE),
  v = runif(n = n, 0, 10000)
)

# Measure computation time
system.time({
  result <- greedy_knapsack(knapsack_objects, W = 3500)
})

result
```

# 1.1.5 Test suits

## Justification that our algorithm is Greedy

Our greedy_knapsack function implements the greedy approximation algorithm by first calculating the value-to-weight ratio for every item. It then sorts the items in descending order based on this ratio, ensuring the most 'efficient' items are considered first. Finally, it iterates through the sorted list, adding each item to the knapsack if it fits within the remaining weight capacity. This approach follows the definition of the greedy algorithm for the knapsack problem and has a computational complexity of O(n log n), dominated by the sorting step.

# 1.1.6 Profile your code and optimize your code


